{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bd5bc-2520-4d67-8cb3-393d1aeed5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "data = pd.read_csv('HCV-Egy-Data.csv')\n",
    "\n",
    "X = data.drop(columns=['Baselinehistological staging'])  \n",
    "y = data['Baselinehistological staging']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(estimator=dt_model, param_grid=dt_param_grid, cv=5, scoring='accuracy')\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "best_dt = dt_grid.best_estimator_\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "\n",
    "display(HTML(\"<h2>Decision Tree Classifier</h2>\"))\n",
    "display(HTML(\"<h3>Mejores Hiperparámetros</h3>\"))\n",
    "display(pd.DataFrame({'Mejores Hiperparámetros': [dt_grid.best_params_]}))\n",
    "\n",
    "display(HTML(\"<h3>Matriz de Confusión</h3>\"))\n",
    "display(pd.DataFrame(confusion_matrix(y_test, y_pred_dt),\n",
    "                     index=[f\"Clase {i}\" for i in sorted(y.unique())],\n",
    "                     columns=[f\"Predicción {i}\" for i in sorted(y.unique())]))\n",
    "\n",
    "report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "display(HTML(\"<h3>Reporte de Clasificación</h3>\"))\n",
    "display(pd.DataFrame(report_dt).transpose())\n",
    "\n",
    "plot_learning_curve(best_dt, \"Curva de Aprendizaje: Decision Tree\", X_train, y_train, cv=5)\n",
    "plt.show()\n",
    "\n",
    "train_mean = np.mean(train_scores[-1])\n",
    "test_mean = np.mean(test_scores[-1])\n",
    "\n",
    "if train_mean > test_mean + 0.1:\n",
    "    print(\"Diagnóstico: El modelo funciona mejor en entrenamiento que en validación.\")\n",
    "elif test_mean < 0.6:\n",
    "    print(\"Diagnóstico: El modelo no generaliza bien.\")\n",
    "else:\n",
    "    print(\"Diagnóstico: El modelo presenta un buen equilibrio entre entrenamiento y validación.\")\n",
    "\n",
    "print(\"\\nConclusiones:\")\n",
    "print(\"1. El modelo de Decision Tree tiene una precisión de X% en los datos de prueba.\")\n",
    "print(\"2. Los hiperparámetros óptimos encontrados fueron:\", best_dt.get_params())\n",
    "print(\"3. Según la curva de aprendizaje, el modelo muestra que el modelo no generaliza bien\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
